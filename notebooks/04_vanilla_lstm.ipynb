{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM\n",
    "\n",
    "2026-01-28\n",
    "\n",
    "Prediction-based LSTM: uses past N timesteps to predict next value. High prediction error = anomaly.\n",
    "Comparing full-size (100 units, SKAB config) vs tiny (16 units) for edge deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path('../data/raw/SKAB/data')\n",
    "\n",
    "files = []\n",
    "for folder in ['valve1', 'valve2', 'other']:\n",
    "    files.extend(sorted((data_dir / folder).glob('*.csv')))\n",
    "\n",
    "feature_cols = ['Accelerometer1RMS', 'Accelerometer2RMS', 'Current', 'Pressure',\n",
    "                'Temperature', 'Thermocouple', 'Voltage', 'Volume Flow RateRMS']\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKAB params\n",
    "TRAIN_SIZE = 400\n",
    "N_STEPS = 5\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "Q = 0.99\n",
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(sequences) - n_steps):\n",
    "        X.append(sequences[i:i+n_steps, :])\n",
    "        y.append(sequences[i+n_steps, :])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm(n_steps, n_features, units):\n",
    "    model = Sequential([\n",
    "        Input(shape=(n_steps, n_features)),\n",
    "        LSTM(units, activation='relu', return_sequences=True),\n",
    "        LSTM(units, activation='relu'),\n",
    "        Dense(n_features)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(files, units, verbose=True):\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    for i, f in enumerate(files):\n",
    "        df = pd.read_csv(f, sep=';', parse_dates=['datetime'], index_col='datetime')\n",
    "        X = df[feature_cols].values\n",
    "        y = df['anomaly'].values\n",
    "        \n",
    "        X_train_raw, X_test_raw = X[:TRAIN_SIZE], X[TRAIN_SIZE:]\n",
    "        y_test = y[TRAIN_SIZE:]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_sc = scaler.fit_transform(X_train_raw)\n",
    "        X_test_sc = scaler.transform(X_test_raw)\n",
    "        \n",
    "        X_tr, y_tr = split_sequences(X_train_sc, N_STEPS)\n",
    "        X_te, y_te_pred = split_sequences(X_test_sc, N_STEPS)\n",
    "        \n",
    "        tf.random.set_seed(0)\n",
    "        np.random.seed(0)\n",
    "        model = build_lstm(N_STEPS, len(feature_cols), units)\n",
    "        model.fit(X_tr, y_tr, validation_split=VAL_SPLIT, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                  verbose=0, shuffle=False,\n",
    "                  callbacks=[EarlyStopping(patience=10, verbose=0),\n",
    "                            ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.0001, verbose=0)])\n",
    "        \n",
    "        train_pred = model.predict(X_tr, verbose=0)\n",
    "        residuals_train = pd.DataFrame(np.abs(y_tr - train_pred)).sum(axis=1)\n",
    "        UCL = residuals_train.quantile(Q) * 5\n",
    "        \n",
    "        test_pred = model.predict(X_te, verbose=0)\n",
    "        residuals_test = pd.DataFrame(np.abs(y_te_pred - test_pred)).sum(axis=1)\n",
    "        pred = (residuals_test > UCL).astype(int).values\n",
    "        \n",
    "        y_test_aligned = y_test[N_STEPS:]\n",
    "        all_y_true.extend(y_test_aligned)\n",
    "        all_y_pred.extend(pred)\n",
    "        \n",
    "        if verbose and (i+1) % 10 == 0:\n",
    "            print(f'{i+1}/{len(files)} files')\n",
    "    \n",
    "    y_true = np.array(all_y_true)\n",
    "    y_pred = np.array(all_y_pred)\n",
    "    \n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    far = fp / (fp + tn) * 100\n",
    "    mar = fn / (fn + tp) * 100\n",
    "    size_kb = len(pickle.dumps(model)) / 1024\n",
    "    \n",
    "    return {'f1': f1, 'far': far, 'mar': mar, 'size_kb': size_kb, 'model': model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-size (100 units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/34 files\n",
      "20/34 files\n",
      "30/34 files\n",
      "F1:  0.48  (SKAB: 0.54)\n",
      "FAR: 10.93% (SKAB: 12.54%)\n",
      "MAR: 65.41% (SKAB: 59.53%)\n",
      "Size: 1494 KB\n"
     ]
    }
   ],
   "source": [
    "results_full = evaluate_lstm(files, units=100)\n",
    "print(f\"F1:  {results_full['f1']:.2f}  (SKAB: 0.54)\")\n",
    "print(f\"FAR: {results_full['far']:.2f}% (SKAB: 12.54%)\")\n",
    "print(f\"MAR: {results_full['mar']:.2f}% (SKAB: 59.53%)\")\n",
    "print(f\"Size: {results_full['size_kb']:.0f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny (16 units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/34 files\n",
      "20/34 files\n",
      "30/34 files\n",
      "F1:  0.37  (full: 0.48)\n",
      "FAR: 3.06% (full: 10.93%)\n",
      "MAR: 76.99% (full: 65.41%)\n",
      "Size: 77 KB (full: 1494 KB)\n"
     ]
    }
   ],
   "source": [
    "results_tiny = evaluate_lstm(files, units=16)\n",
    "print(f\"F1:  {results_tiny['f1']:.2f}  (full: {results_full['f1']:.2f})\")\n",
    "print(f\"FAR: {results_tiny['far']:.2f}% (full: {results_full['far']:.2f}%)\")\n",
    "print(f\"MAR: {results_tiny['mar']:.2f}% (full: {results_full['mar']:.2f}%)\")\n",
    "print(f\"Size: {results_tiny['size_kb']:.0f} KB (full: {results_full['size_kb']:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>FAR %</th>\n",
       "      <th>MAR %</th>\n",
       "      <th>Size KB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Full (100 units)</td>\n",
       "      <td>0.480784</td>\n",
       "      <td>10.934192</td>\n",
       "      <td>65.408115</td>\n",
       "      <td>1494.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiny (16 units)</td>\n",
       "      <td>0.366324</td>\n",
       "      <td>3.055683</td>\n",
       "      <td>76.993577</td>\n",
       "      <td>76.786133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model        F1      FAR %      MAR %      Size KB\n",
       "0  Full (100 units)  0.480784  10.934192  65.408115  1494.289062\n",
       "1   Tiny (16 units)  0.366324   3.055683  76.993577    76.786133"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Full (100 units)', 'Tiny (16 units)'],\n",
    "    'F1': [results_full['f1'], results_tiny['f1']],\n",
    "    'FAR %': [results_full['far'], results_tiny['far']],\n",
    "    'MAR %': [results_full['mar'], results_tiny['mar']],\n",
    "    'Size KB': [results_full['size_kb'], results_tiny['size_kb']]\n",
    "})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 drop: 23.8%\n",
      "Size reduction: 94.9%\n"
     ]
    }
   ],
   "source": [
    "f1_drop = (results_full['f1'] - results_tiny['f1']) / results_full['f1'] * 100\n",
    "size_reduction = (results_full['size_kb'] - results_tiny['size_kb']) / results_full['size_kb'] * 100\n",
    "print(f\"F1 drop: {f1_drop:.1f}%\")\n",
    "print(f\"Size reduction: {size_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full (100 units): 55.8 ms\n",
      "Tiny (16 units): 67.9 ms\n"
     ]
    }
   ],
   "source": [
    "# prepare sample data\n",
    "sample = pd.read_csv(files[5], sep=';', parse_dates=['datetime'], index_col='datetime')\n",
    "X_s = sample[feature_cols].values\n",
    "sc = StandardScaler()\n",
    "X_sc = sc.fit_transform(X_s[:TRAIN_SIZE])\n",
    "X_seq, _ = split_sequences(X_sc, N_STEPS)\n",
    "single = X_seq[:1]\n",
    "\n",
    "# train quick models for latency test\n",
    "tf.random.set_seed(0)\n",
    "m_full = build_lstm(N_STEPS, 8, 100)\n",
    "m_full.fit(X_seq, X_seq[:, -1, :], epochs=3, verbose=0)\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "m_tiny = build_lstm(N_STEPS, 8, 16)\n",
    "m_tiny.fit(X_seq, X_seq[:, -1, :], epochs=3, verbose=0)\n",
    "\n",
    "# warmup\n",
    "m_full.predict(single, verbose=0)\n",
    "m_tiny.predict(single, verbose=0)\n",
    "\n",
    "# full\n",
    "times = []\n",
    "for _ in range(500):\n",
    "    t0 = time.perf_counter()\n",
    "    m_full.predict(single, verbose=0)\n",
    "    times.append(time.perf_counter() - t0)\n",
    "lat_full = np.median(times) * 1000\n",
    "\n",
    "# tiny\n",
    "times = []\n",
    "for _ in range(500):\n",
    "    t0 = time.perf_counter()\n",
    "    m_tiny.predict(single, verbose=0)\n",
    "    times.append(time.perf_counter() - t0)\n",
    "lat_tiny = np.median(times) * 1000\n",
    "\n",
    "print(f\"Full (100 units): {lat_full:.1f} ms\")\n",
    "print(f\"Tiny (16 units): {lat_tiny:.1f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Shrinking 100â†’16 units: 95% size reduction, 26% F1 drop. Latency similar due to Keras overhead.\n",
    "TF Lite deployment should show bigger latency difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
